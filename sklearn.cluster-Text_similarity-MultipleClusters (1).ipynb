{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Import modules</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `><:@` not found.\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.metrics import edit_distance\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Import data for future clusters name and values from CSV file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data for future clusters name and values from CSV file\n",
    "\n",
    "clusters = pd.read_csv(\"sp500names_unique.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Cleaning the Cluster name data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the Cluster name data\n",
    "\n",
    "cluster_list = clusters['COMNAM'].tolist()\n",
    "cluster_list2 = [w.replace(' INC', '').replace(' CO', '').replace(' LTD', '') for w in cluster_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Import main data from CSV file</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">File should be uploaded in Jupyter directory</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">nrows = means how many rows do you need from original file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import main data from CSV file\n",
    "\n",
    "df = pd.read_csv(\"indivs18.csv\", nrows=100, encoding = \"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Insert additional column that will copy and save for further usage Index from original file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert additional column that will copy and save for further usage Index from original file\n",
    "\n",
    "df.insert(0, column='index1', value=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Delete all rows where column \"Employer\" is empty</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows where column \"Employer\" is empty\n",
    "\n",
    "df = df.dropna(subset=[\"Employer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Make all entries in column \"Employer\" lowercase</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all entries in column \"Employer\" lowercase\n",
    "\n",
    "df['Employer'] = df['Employer'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Clean up column \"Employer\" - select only rows that does NOT contain certain values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up column \"Employer\" - select only rows that does NOT contain certain values\n",
    "\n",
    "df = df[(df.Employer != \"not employed\") & (df.Employer != \"self employed\") & (df.Employer != \"none\") & (df.Employer != \"self-employed\") & (df.Employer != \"self\") & (df.Employer != \"retired\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Make column list lowercase</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column list lowercase\n",
    "\n",
    "column_values1 = list(map(lambda x:x.lower(), cluster_list2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Add to each column name \"_cluster\" to use it for Cluster column creation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add to each column name \"_cluster\" to use it for Cluster column creation\n",
    "\n",
    "string = '_cluster'\n",
    "column_names1 = [x + string for x in cluster_list2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Create a new empty dataframe with Columns for each cluster(company name) and populate columns with values that we will compare later to values in column \"Employer\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a new empty dataframe with Columns for each cluster(company name) \n",
    "and populate columns with values that we will compare later to values in column \"Employer\"\n",
    "\"\"\"\n",
    "\n",
    "df1 = pd.DataFrame(columns = column_names1, index=df.index)\n",
    "i = 0\n",
    "for col in df1.columns:\n",
    "    df1[col] = column_values1[i]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Combine two dataframe with clusters with original one</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two dataframe with clusters with original one\n",
    "\n",
    "df2 = pd.concat([df, df1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Select needed columns for creating Cluster_distance columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select needed columns for creating Cluster_distance columns\n",
    "\n",
    "test_list = df2.columns[25:].tolist()\n",
    "print(test_list[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Changing column names from \"cluster\" to \"distance\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing column names from \"cluster\" to \"distance\"\n",
    "\n",
    "test_list2 = [w.replace('_cluster', '_distance') for w in test_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Create a new empty dataframe with Columns for each cluster_distance</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new empty dataframe with Columns for each cluster_distance\n",
    "\n",
    "df3 = pd.DataFrame(columns = test_list2, index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Populate columns for Cluster_distance with Score metrics. Compare values from each of Cluster columns and value in column \"Employer\". This line will take 90 % of all time required</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b3fa949ba1468abc26c1f93cefcb18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Calculating Score_Metrics', max=2239, style=ProgressStyle(desâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Populate columns for Cluster_distance with Score metrics. \n",
    "Compare values from each of Cluster columns and value in column \"Employer\". This line will take 90 % of all time required\n",
    "\"\"\"\n",
    "\n",
    "n = 25\n",
    "for col in tqdm(df3, total=2239, desc=\"Calculating Score_Metrics\"):\n",
    "    df3[col] = df2.iloc[:, [22,n]].apply(lambda x: edit_distance(*x), axis=1)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Combine all data into a new combined dataframe</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all data into a new combined dataframe\n",
    "\n",
    "df4 = pd.concat([df2, df3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Selecting data for \"Cluster_NAME\" final result output column</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting data for \"Cluster_NAME\" final result output column\n",
    "\n",
    "df5 = df4.iloc[:, np.r_[0,2,22,25:2263]]\n",
    "\n",
    "# Selecting data for \"Cluster_Score\" final result output column\n",
    "\n",
    "df7 = df4.iloc[:, np.r_[0,2,22,2264:4503]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Selecting data for \"Cluster_Score\" final result output column</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Grouping data for \"Cluster_NAME\" final result output column</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data for \"Cluster_NAME\" final result output column\n",
    "\n",
    "df6 = df5.melt(id_vars=['index1', \"FECTransID\", \"Employer\"])\n",
    "group = df6.groupby([\"index1\", \"FECTransID\", \"Employer\", \"variable\", \"value\"]).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Grouping data for \"Cluster_Score\" final result output column</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data for \"Cluster_Score\" final result output column\n",
    "\n",
    "df8 = df7.melt(id_vars=[\"index1\", \"FECTransID\", \"Employer\"])\n",
    "group1 = df8.groupby([\"index1\", \"FECTransID\", \"Employer\", \"variable\", \"value\"]).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Adding column for \"Cluster_Score\" column into combined dataframe</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column for \"Cluster_Score\" column into combined dataframe\n",
    "\n",
    "group[\"Test_value\"] = group1[\"value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Drop technically created columns that we don't need in a final result</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop technically created columns that we don't need in a final result\n",
    "\n",
    "group.drop(['variable', \"counts\"], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Rename columns as we need it</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns as we need it\n",
    "\n",
    "group.rename(columns = {'value':'Cluster_NAME', 'Test_value':'Cluster_Score'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Select only data that has Score value less than 10</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only data that has Score value less than 10\n",
    "\n",
    "group = group[(group.Cluster_Score <= 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Check before saving if we did everything correct and get a needed output</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Save results into file. File will be in Jupyter directory</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results into file. File will be in Jupyter directory\n",
    "\n",
    "group.to_csv(\"New_structure_100_rows_2239_clusters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">For speed testing - place needed code lines between \"\"\" \"\"\". Following lines will test the code for 1M rows from original file and 1 cluster, result displayed in seconds</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.24129309999998"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For speed testing - place needed code lines between \"\"\" \"\"\". \n",
    "Following lines will test the code for 1M rows from original file and 1 cluster, result displayed in seconds\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import timeit\n",
    "s = \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.metrics import edit_distance\n",
    "df = pd.read_csv(\"indivs18.csv\", nrows=1000000, low_memory=False, encoding = \"ISO-8859-1\")\n",
    "df = df.dropna(subset=[\"Employer\"])\n",
    "df['Employer'] = df['Employer'].str.lower()\n",
    "df = df[(df.Employer != \"not employed\") & (df.Employer != \"self employed\") & (df.Employer != \"none\") & (df.Employer != \"self-employed\") & (df.Employer != \"self\") & (df.Employer != \"retired\")]\n",
    "df[\"Apple_cluster\"] = \"apple\"\n",
    "df[\"ips_ht_distance\"] = df.loc[:, [\"Employer\",\"Apple_cluster\"]].apply(lambda x: edit_distance(*x), axis=1)\n",
    "\"\"\"\n",
    "timeit.timeit(stmt=s, number=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
